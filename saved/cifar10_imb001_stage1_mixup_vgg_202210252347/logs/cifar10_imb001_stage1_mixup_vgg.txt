2022-10-25 23:47:48,359 
Namespace(cfg='./config/cifar10/cifar10_imb001_stage1_mixup_vgg.yaml', opts=['rho', '1.', 'gamma', '0.'])
2022-10-25 23:47:48,359 
alpha: 1.0
backbone: vgg16
batch_size: 128
cos: False
data_path: ./data/cifar10
dataset: cifar10
deterministic: False
dist_backend: nccl
dist_url: tcp://224.66.41.62:23456
distributed: False
gamma: 0.0
gpu: 0
head_class_idx: [0, 3]
imb_factor: 0.01
log_dir: logs
lr: 0.1
lr_factor: None
med_class_idx: [3, 7]
mixup: True
mode: stage1
model_dir: ckps
momentum: 0.9
multiprocessing_distributed: False
name: cifar10_imb001_stage1_mixup_vgg
num_classes: 10
num_epochs: 200
print_freq: 40
rank: -1
resume: 
rho: 1.0
shift_bn: False
smooth_head: None
smooth_tail: None
tail_class_idx: [7, 10]
weight_decay: 0.0002
workers: 1
world_size: -1
2022-10-25 23:47:48,420 Use GPU: 0 for training
2022-10-25 23:47:49,268 
Namespace(cfg='./config/cifar10/cifar10_imb001_stage1_mixup_vgg.yaml', opts=['rho', '0.1', 'gamma', '0.'])
2022-10-25 23:47:49,268 
alpha: 1.0
backbone: vgg16
batch_size: 128
cos: False
data_path: ./data/cifar10
dataset: cifar10
deterministic: False
dist_backend: nccl
dist_url: tcp://224.66.41.62:23456
distributed: False
gamma: 0.0
gpu: 0
head_class_idx: [0, 3]
imb_factor: 0.01
log_dir: logs
lr: 0.1
lr_factor: None
med_class_idx: [3, 7]
mixup: True
mode: stage1
model_dir: ckps
momentum: 0.9
multiprocessing_distributed: False
name: cifar10_imb001_stage1_mixup_vgg
num_classes: 10
num_epochs: 200
print_freq: 40
rank: -1
resume: 
rho: 0.1
shift_bn: False
smooth_head: None
smooth_tail: None
tail_class_idx: [7, 10]
weight_decay: 0.0002
workers: 1
world_size: -1
2022-10-25 23:47:49,294 Use GPU: 0 for training
2022-10-25 23:47:50,156 
Namespace(cfg='./config/cifar10/cifar10_imb001_stage1_mixup_vgg.yaml', opts=['rho', '0.5', 'gamma', '0.'])
2022-10-25 23:47:50,157 
alpha: 1.0
backbone: vgg16
batch_size: 128
cos: False
data_path: ./data/cifar10
dataset: cifar10
deterministic: False
dist_backend: nccl
dist_url: tcp://224.66.41.62:23456
distributed: False
gamma: 0.0
gpu: 0
head_class_idx: [0, 3]
imb_factor: 0.01
log_dir: logs
lr: 0.1
lr_factor: None
med_class_idx: [3, 7]
mixup: True
mode: stage1
model_dir: ckps
momentum: 0.9
multiprocessing_distributed: False
name: cifar10_imb001_stage1_mixup_vgg
num_classes: 10
num_epochs: 200
print_freq: 40
rank: -1
resume: 
rho: 0.5
shift_bn: False
smooth_head: None
smooth_tail: None
tail_class_idx: [7, 10]
weight_decay: 0.0002
workers: 1
world_size: -1
2022-10-25 23:47:50,178 Use GPU: 0 for training
